# -----------------------------------------------------------------------------
# DSXâ€‘Connect Helm values (production defaults)
# - External DSXA is assumed (dsxa-scanner.enabled=false)
# - REQUIRED: set global.env.DSXCONNECT_SCANNER__SCAN_BINARY_URL to your DSXA URL
# - API/workers LOG_LEVEL default to 'info'
# - Override image tag at install time: --set-string global.image.tag=<version>
# -----------------------------------------------------------------------------
# Global settings used by all dsx-connect subcharts
global:
  # Minimal, common env most users need to touch. Everything else is set in templates with sane defaults.
  env:
    DSXCONNECT_APP_ENV: dev # dev, stg, prod
    DSXCONNECTOR_API_KEY: api-key-NOT-FOR-PRODUCTION
    # REQUIRED when (dsxa-scanner.enabled=false): set to your external DSXA endpoint
    DSXCONNECT_SCANNER__SCAN_BINARY_URL: "http://external-dsxa:5000/scan/binary/v2"
    # Results/stats DB URL (redis://... => Redis, anything else => in-memory)
    DSXCONNECT_RESULTS_DB: redis://redis:6379/3

  # DIANNA (Deep Instinct) settings applied to API and workers
  dianna:
    # Base URL of Deep Instinct management console, e.g., https://di.example.com
    managementUrl: ""
    # API token for DIANNA REST API (use a Secret in production; this values entry is for convenience)
    apiToken: ""
    # TLS verification and optional custom CA bundle
    verifyTls: true
    caBundle: ""
    # Upload behavior
    chunkSize: 4194304   # 4 MiB
    timeout: 60          # seconds
    # Automatically enqueue DI analysis when a malicious verdict is observed
    autoOnMalicious: false
    # Result polling after upload completes (dianna worker only)
    pollResultsEnabled: true
    pollIntervalSeconds: 5
    pollTimeoutSeconds: 900

  # Optional shared image defaults (subcharts fall back to these when set)
  image:
    repository: dsxconnect/dsx-connect
    tag: ""
    pullPolicy: IfNotPresent
    # Note: When installing from an OCI chart with --version=X.Y.Z, the default image tag will be that chart's appVersion.

  # Optional scanner service hints used when dsxa-scanner subchart is enabled
  scanner:
    # serviceName: "dsxa-scanner"   # optional: explicit K8s service name (defaults to <release>-dsxa-scanner)
    # port: 5000                     # optional: override port (defaults to 5000)
    # scheme: http                   # optional: http|https (defaults to http)

# typical deployments would have dsxa-scanners in their own cluster and namespace, but for if all that's needed
# is a single dsxa-scanner pod that only supports scan/binary/v2 (file size <= 2GB), then enable here.
dsxa-scanner:
  enabled: false

dsx-connect-api:
  enabled: true
  service:
    port: 80
  tls:
    enabled: false
    port: 443
    secretName: ""
    mountPath: "/app/certs"
  env:
    LOG_LEVEL: info
  # Optional shared data volume for /app/data so API can read DB files
  dataVolume:
    enabled: false
    # Provide one of the following sources (prefer a RWX PVC in multi-node clusters):
    existingClaim: ""   # Name of an existing PersistentVolumeClaim (RWX recommended)
    hostPath: ""        # Node path for single-node/dev only

dsx-connect-scan-request-worker:
  enabled: true
  replicaCount: 1
  env:
    LOG_LEVEL: info
  celery:
    # queue computed from DSXCONNECT_APP_ENV in template unless overridden here
    # queue: "dev.dsx_connect.scans.request"
    # Concurrency = Celery workers per pod. Combine with replicaCount for total parallelism.
    concurrency: 1

dsx-connect-verdict-action-worker:
  enabled: true
  replicaCount: 1
  env:
    LOG_LEVEL: info
  celery:
    # queue: "dev.dsx_connect.scans.verdict"
    # Concurrency = Celery workers per pod.
    concurrency: 1

dsx-connect-results-worker:
  enabled: true
  replicaCount: 1
  env:
    LOG_LEVEL: info
    DSXCONNECT_SYSLOG__TRANSPORT: tcp
  celery:
    # queue: "dev.dsx_connect.scans.result"
    # Concurrency = Celery workers per pod.
    concurrency: 1
  # Optional shared data volume for /app/data so worker and API share DB files
  dataVolume:
    enabled: false
    existingClaim: ""
    hostPath: ""

dsx-connect-notification-worker:
  enabled: true
  replicaCount: 1
  # image:
  env:
    LOG_LEVEL: info
  celery:
    # queue: "dev.dsx_connect.scans.result.notify"
    # Concurrency = Celery workers per pod.
    concurrency: 1

dsx-connect-dianna-worker:
  enabled: true
  replicaCount: 1
  env:
    LOG_LEVEL: info
  celery:
    # queue: "dev.dsx_connect.analyze.dianna"
    # Concurrency = Celery workers per pod.
    concurrency: 1

redis:
  enabled: true
  image:
    repository: redis
    tag: "7-alpine"
  command:
    - "redis-server"
    - "--notify-keyspace-events"
    - "Ex"
    - "--maxmemory-policy"
    - "allkeys-lru"
    - "--timeout"
    - "0"
    - "--tcp-keepalive"
    - "300"
    - "--appendonly"
    - "no"
  healthcheck:
    test: ["redis-cli", "ping"]
    interval: 10
    timeout: 3
    retries: 5
    startPeriod: 10

rsyslog:
  enabled: false

ingress:
  enabled: false
  host: "dsx-connect.127.0.0.1.nip.io"
  ingressClassName: ""
  # For TLS, the secret must be created separately (e.g., kubectl create secret tls my-ingress-tls --cert=... --key=...)
  # and its name should be specified in the dsx-connect-api.tls.secretName if it's the same secret.
  # If you have a separate secret for Ingress, specify it here:
  # tlsSecretName: ""
